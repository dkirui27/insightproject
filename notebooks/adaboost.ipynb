{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "import lightgbm as lgb\n",
    "from fbprophet import Prophet\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "#importing a scoring metric to compare methods\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"../data/processed/train_features.csv\")\n",
    "train_labels = pd.read_csv(\"../data/processed/train_labels.csv\")\n",
    "test_features = pd.read_csv(\"../data/processed/test_features.csv\")\n",
    "test_labels = pd.read_csv(\"../data/processed/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## BEGINNING BOOSTING MODEL ##########################\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfavoritenumber = 13\n",
    "seed = myfavoritenumber\n",
    "np.random.seed(seed)\n",
    "\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_features\n",
    "y = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.set_index(['measurement_date', 'user_code'], inplace=True) #reseting the index\n",
    "y.set_index(['measurement_date', 'user_code'], inplace=True) #reseting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = bdt.fit(X, y.values.ravel()) #.ravel converts from col vec to 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   n_estimators=200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_features\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.set_index(['measurement_date', 'user_code'], inplace=True) #reseting the index\n",
    "y_test.set_index(['measurement_date', 'user_code'], inplace=True) #reseting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_predictions = mod.predict(X_test)\n",
    "bdt_probs = mod.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8639918051708217"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_value = roc_auc_score(y_test, bdt_probs)\n",
    "roc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results = confusion_matrix(y_test, bdt_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[537  71]\n",
      " [ 60  54]]\n",
      "Accuracy Score : 0.8185595567867036\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       608\n",
      "           1       0.43      0.47      0.45       114\n",
      "\n",
      "    accuracy                           0.82       722\n",
      "   macro avg       0.67      0.68      0.67       722\n",
      "weighted avg       0.83      0.82      0.82       722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(y_test, bdt_predictions)) \n",
    "print('Report : ')\n",
    "print(classification_report(y_test, bdt_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
