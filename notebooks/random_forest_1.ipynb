{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import streamlit as st\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import os\n",
    "import altair as alt\n",
    "import pydeck as pdk\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "import lightgbm as lgb\n",
    "from fbprophet import Prophet\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#importing a scoring metric to compare methods\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "processed2 = pd.read_csv(\"../data/processed/processed.csv\") #the .. goes one directory up (two periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2.measurement_date = pd.to_datetime(processed2.measurement_date, format = '%Y-%m-%d')\n",
    "processed2.set_index(['measurement_date', 'user_code'], inplace=True) #reseting the index\n",
    "processed2['distance_yds'] = (processed2['distance'] * 1.0936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2['active_calories_burned_norm'] = preprocessing.scale(processed2['active_calories_burned'])\n",
    "processed2['steps_count_norm'] = preprocessing.scale(processed2['steps_count'])\n",
    "processed2['distance_norm'] = preprocessing.scale(processed2['distance'])\n",
    "processed2['steps_speed_norm'] = preprocessing.scale(processed2['steps_speed'])\n",
    "processed2['body_temperature_avg_norm'] = preprocessing.scale(processed2['body_temperature_avg'])\n",
    "processed2['pulse_average_norm'] = preprocessing.scale(processed2['pulse_average'])\n",
    "processed2['stand_hours_total_norm'] = preprocessing.scale(processed2['stand_hours_total'])\n",
    "processed2['total_number_of_flights_climbed_norm'] = preprocessing.scale(processed2['total_number_of_flights_climbed'])\n",
    "processed2['pulse_min_norm'] = preprocessing.scale(processed2['pulse_min'])\n",
    "processed2['pulse_max_norm'] = preprocessing.scale(processed2['pulse_max'])\n",
    "processed2['average_spo2_value_norm'] = preprocessing.scale(processed2['average_spo2_value'])\n",
    "processed2['distance_mi_norm'] = preprocessing.scale(processed2['distance_mi'])\n",
    "processed2['ACWR_norm'] = preprocessing.scale(processed2['ACWR'])\n",
    "processed2['height_in_norm'] = preprocessing.scale(processed2['height_in'])\n",
    "processed2['weight_lbs_norm'] = preprocessing.scale(processed2['weight_lbs'])\n",
    "processed2['rmssd_norm'] = preprocessing.scale(processed2['rmssd'])\n",
    "processed2['bpm_norm'] = preprocessing.scale(processed2['bpm'])\n",
    "processed2['heart_rate_norm'] = preprocessing.scale(processed2['heart_rate'])\n",
    "processed2['BMI_norm'] = preprocessing.scale(processed2['BMI'])\n",
    "processed2['distance_yds_norm'] = preprocessing.scale(processed2['distance_yds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2.reset_index(inplace=True) #date needs to be an index before you can do test/train split\n",
    "processed2.set_index(['measurement_date', 'user_code'], inplace=True) #reseting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.096045197740113"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed2.over_train.mean() #about 10% in the overtraining class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing a train/test split\n",
    "range_train = pd.date_range(start = '2020-01-01', end = '2020-04-16') #doing an 80/20 split\n",
    "df_train = processed2.loc[range_train]\n",
    "\n",
    "range_test = pd.date_range(start = '2020-04-17', end = '2020-05-13')\n",
    "df_test = processed2.loc[range_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidkirui/anaconda3/envs/insight/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "drop = ['steps_count',\n",
    "       'active_calories_burned', 'distance', 'steps_speed',\n",
    "       'body_temperature_avg', 'pulse_average', 'stand_hours_total',\n",
    "       'total_number_of_flights_climbed', 'pulse_min', 'pulse_max',\n",
    "       'average_spo2_value', 'distance_mi', 'ACWR', 'height', 'weight',\n",
    "       'height_in', 'weight_lbs', 'rmssd', 'pnn50', 'bpm', 'lnrmssd',\n",
    "       'is_resting', 'heart_rate', 'BMI', 'lnrmssd_z', 'ACWR_z','distance_yds', 'distance_norm']\n",
    "#ONLY RUN THIS ONCE!\n",
    "df_train.drop(drop, axis = 1, inplace=True)  #removing non-normalized features and other features that will not be included\n",
    "df_test.drop(drop, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing RF after dropping HRV ::::\n",
    "#del df_train['ACWR_norm'] #removing ACWR\n",
    "del df_train['rmssd_norm'] #removing HRV\n",
    "#del df_test['ACWR_norm'] #removing ACWR\n",
    "del df_test['rmssd_norm'] #removing HRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"../data/processed/df_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"../data/processed/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##converting data to arrays for RF\n",
    "#labels are the values that we want to predict:\n",
    "train_labels = df_train['over_train']\n",
    "\n",
    "#remove the labels from the features\n",
    "#axis 1 refers to the columns\n",
    "train_features = df_train.drop('over_train', axis = 1)\n",
    "\n",
    "#Saving feature names for later use\n",
    "feature_list = list(train_features.columns)\n",
    "\n",
    "#convert to numpy array\n",
    "features_train = np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.to_csv(\"../data/processed/train_labels.csv\")\n",
    "train_features.to_csv(\"../data/processed/train_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "\n",
    "#setting random number seed\n",
    "myfavoritenumber = 13\n",
    "seed = myfavoritenumber\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt',\n",
    "                               class_weight = {0:2,1:1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 2, 1: 1}, max_features='sqrt',\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual class predictions\n",
    "##converting data to arrays for RF\n",
    "#labels are the values that we want to predict:\n",
    "test_labels = df_test['over_train']\n",
    "\n",
    "#remove the labels from the features\n",
    "#axis 1 refers to the columns\n",
    "test_features = df_test.drop('over_train', axis = 1)\n",
    "\n",
    "\n",
    "#Saving feature names for later use\n",
    "feature_list = list(test_features.columns)\n",
    "\n",
    "#convert to numpy array\n",
    "features_test = np.array(test_features)\n",
    "\n",
    "rf_predictions = model.predict(test_features)\n",
    "rf_probs = model.predict_proba(test_features)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv(\"../data/processed/test_labels.csv\")\n",
    "test_features.to_csv(\"../data/processed/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8743002654662974"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(test_labels, rf_probs)\n",
    "roc_value #HRV still in there. \n",
    "#0.8639485226223453 (HRV in, ACWR out)\n",
    "#0.8811677631578948 (HRV out, ACWR in) <- this is interesting!  bc you don't need HRV to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results = confusion_matrix(test_labels, rf_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[569  39]\n",
      " [ 70  44]]\n",
      "Accuracy Score : 0.8490304709141274\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       608\n",
      "           1       0.53      0.39      0.45       114\n",
      "\n",
      "    accuracy                           0.85       722\n",
      "   macro avg       0.71      0.66      0.68       722\n",
      "weighted avg       0.83      0.85      0.84       722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(test_labels, rf_predictions)) \n",
    "print('Report : ')\n",
    "print(classification_report(test_labels, rf_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
